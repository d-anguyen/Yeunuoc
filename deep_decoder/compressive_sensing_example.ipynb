{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressive sensing example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num GPUs 0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import sigpy.mri as mr\n",
    "\n",
    "import sigpy as sp\n",
    "import sigpy.mri as mr\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from include import *\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "#from models import *\n",
    "#from utils.denoising_utils import *\n",
    "\n",
    "GPU = True\n",
    "if GPU == True:\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    print(\"num GPUs\",torch.cuda.device_count())\n",
    "else:\n",
    "    dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def crop_center(img,cropx,cropy):\n",
    "    #y,x = img.shape\n",
    "    y = img.shape[-2]\n",
    "    x = img.shape[-1]\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)\n",
    "    if len(img.shape) == 2:\n",
    "        return img[starty:starty+cropy,startx:startx+cropx]\n",
    "    if len(img.shape) == 3:\n",
    "        return img[0,starty:starty+cropy,startx:startx+cropx]\n",
    "\n",
    "path = './test_data/'\n",
    "img_name = \"poster\"\n",
    "#img_name = \"F16_GT\"\n",
    "#img_name = \"sf4_rgb\"\n",
    "#img_name  = 'library'\n",
    "img_path = path + img_name + \".png\"\n",
    "\n",
    "img_pil = Image.open(img_path)\n",
    "img_np = pil_to_np(img_pil)\n",
    "\n",
    "img_np_small = np.array([crop_center(img_np[0],128,128)])\n",
    "img_var = np_to_var(img_np_small).type(dtype)\n",
    "output_depth = img_np.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = img_var.view(-1, np.prod(img_var.shape) )\n",
    "n = X.shape[1]\n",
    "m = int(n/3)\n",
    "A = torch.empty(n,m).uniform_(-1, 1).type(dtype)\n",
    "A *= 1/np.sqrt(m)\n",
    "\n",
    "def forwardm(img_var):\n",
    "    X = img_var.view(-1 , np.prod(img_var.shape) ) \n",
    "    return torch.mm(X,A)\n",
    "\n",
    "measurement = forwardm(img_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DD reconstruction and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net_input(num_channels,w=128,h=128):\n",
    "    totalupsample = 2**len(num_channels)\n",
    "    width = int(128/totalupsample)\n",
    "    height = int(128/totalupsample)\n",
    "    shape = [1,num_channels[0], width, height]\n",
    "    net_input = Variable(torch.zeros(shape)).type(dtype)\n",
    "    net_input.data.uniform_()\n",
    "    net_input.data *= 1./10\n",
    "    return net_input\n",
    "\n",
    "def get_random_img(num_channels,ni=None):\n",
    "    if ni is None:\n",
    "        ni = get_net_input(num_channels)\n",
    "    net = decodernw(1,num_channels_up=num_channels,need_sigmoid=True).type(dtype)\n",
    "    print(\"generated random image with\", num_channels, \" network has \", num_param(net) )\n",
    "    return net(ni)\n",
    "\n",
    "def myimgshow(plt,img):\n",
    "    if(img.shape[0] == 1):\n",
    "        plt.imshow(np.clip(img[0],0,1),cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(np.clip(img.transpose(1, 2, 0),0,1))\n",
    "    plt.axis('off')    \n",
    "    \n",
    "def plot_img(img_ref): \n",
    "    fig = plt.figure(figsize = (15,15)) # create a 5 x 5 figure   \n",
    "    ax1 = fig.add_subplot(231)\n",
    "    ax1.imshow(img_ref,cmap='gray')\n",
    "    #ax1.set_title('Original image')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "def init_weights(net):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            #m.weight.data.uniform_()\n",
    "            #torch.nn.init.xavier_uniform(m.weight)\n",
    "            #nn.init.uniform_(m.weight)\n",
    "            torch.nn.init.normal_(m.weight)\n",
    "\n",
    "def snr(x_hat,x_true):\n",
    "    x_hat = x_hat.flatten()\n",
    "    x_true = x_true.flatten()\n",
    "    mse= np.sum( np.square(x_hat-x_true) )\n",
    "    #snr_ = 10.*np.log(maxv**2/mse)/np.log(10.)\n",
    "    snr_ = mse / np.sum( np.square(x_true) )\n",
    "    return snr_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dd_recovery(measurement,img_var,num_channnels,num_iter=6000,apply_f=forwardm,ni=None):\n",
    "    net = decodernw(1,num_channels_up=num_channels,need_sigmoid=True).type(dtype)\n",
    "    #net.apply(init_weights)\n",
    "    mse_n, mse_t, ni, net = fit( num_channels=num_channels,\n",
    "                                net_input=ni,\n",
    "                        reg_noise_std=0.0,num_iter=num_iter,LR = 0.005,\n",
    "                        img_noisy_var=measurement.type(dtype),\n",
    "                        net=net,apply_f = apply_f,img_clean_var=img_var.type(dtype),\n",
    "                        upsample_mode='bilinear',\n",
    "                        )\n",
    "    print(num_param(net))\n",
    "    out_img_var = net( ni.type(dtype) )\n",
    "    return out_img_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example reconstruction\n",
    "\n",
    "This demonstrates that reconstruction with a deep decoder works well, but a deconvolutional decoder does not enable good reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=22\n",
    "num_channels = [k]*4\n",
    "measurement = forwardm(img_var).type(dtype)\n",
    "out_img_var = dd_recovery(measurement,img_var,num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dconv_recovery(img_var):\n",
    "    measurement = forwardm(img_var).type(dtype)\n",
    "    num_channels = [6]*6\n",
    "    net = deconv_decoder(1,num_channels_up=num_channels,filter_size=4,stride=2,padding=1).type(dtype)\n",
    "    mse_n, mse_t, ni, net = fit( num_channels=num_channels,\n",
    "                        reg_noise_std=0.0,num_iter=5000,LR = 0.0025,\n",
    "                        img_noisy_var=measurement,\n",
    "                        net=net,apply_f = forwardm,img_clean_var=img_var.type(dtype),\n",
    "                        upsample_mode='deconv' )\n",
    "    print(num_param(net))\n",
    "    out_img_var = net( ni.type(dtype) )\n",
    "    return out_img_var\n",
    "\n",
    "out_img_dc_var = dconv_recovery(img_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_img(img_var.data.cpu().numpy()[0,0])\n",
    "#plot_img(out_img_var.data.cpu().numpy()[0,0])\n",
    "#plot_img(out_img_dc_var.data.cpu().numpy()[0,0])\n",
    "\n",
    "def savefig(filename,img):\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(filename,bbox_inches='tight')\n",
    "    \n",
    "savefig(img_name + '_orig.png',img_var.data.cpu().numpy()[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressive sensing on random images\n",
    "\n",
    "Our main result shows that taking random linear measurements on the order of the number of parameters of the deep decoder is suffient for recovery is possible. In order to see whether that is also necessary and thus the number of parameters captures the complexity of the range space of the deep decoder, we conduct the following experiment to recover an image in the range of the deep decoder.\n",
    "\n",
    "In order to generate an image, we can in principle simply choose the coefficients of the deep decoder at random. However, for a deep decoder with a fixed number of parameters, this tends to generate simple images, in that often a deep decoder with much fewer coefficients can represent it well. To ensure that we generate a sufficiently complex image, we generate an image in the range of the generator by finding the best representation of noise with the deep decoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numpoints = 8\n",
    "ms = [ int(100*np.exp(5.5/numpoints*i)) for i in range(numpoints) ] #[100,200,,17000]\n",
    "print(ms)\n",
    "ks = [10,20,30,50,150,250]\n",
    "err = np.zeros((len(ms), len(ks)))\n",
    "\n",
    "numit = 10\n",
    "\n",
    "for q in range(numit):\n",
    "    for j,m in enumerate(ms):\n",
    "        for ell,k in enumerate(ks):\n",
    "            # generate input\n",
    "            num_channels = [k]*4\n",
    "            ni = get_net_input(num_channels)\n",
    "        \n",
    "            # get random noise, and find approximation to it in the range of the generator\n",
    "            img_var.data.uniform_()\n",
    "            img_approx = Variable(dd_recovery(img_var,img_var,num_channels,ni=ni,apply_f=None,num_iter=3000))\n",
    "\n",
    "            print(\"number useful variables / number observations\", (k**2*4 + k) /m)\n",
    "            print(\"number observations / number of variables\", m/n)\n",
    "            print(\"m,n,nump\",m,n,k**2*4 + k)\n",
    "            \n",
    "            # generate random matrix\n",
    "            A = 10*torch.empty(n,m).normal_(0, 1/np.sqrt(m)).type(dtype)\n",
    "            \n",
    "            def forwardm(img):\n",
    "                X = img.view(-1 , np.prod(img.shape) )\n",
    "                return torch.mm(X,A)\n",
    "\n",
    "            measurement = forwardm(img_approx).type(dtype)\n",
    "            out_img_var = dd_recovery(measurement,img_approx,num_channels,ni=ni,apply_f=forwardm,num_iter=10000)\n",
    "    \n",
    "            #plot_img(img_approx.data.cpu().numpy()[0,0])\n",
    "            #plot_img(out_img_var.data.cpu().numpy()[0,0])\n",
    "    \n",
    "            error = snr(out_img_var.data.cpu().numpy()[0] , img_approx.data.cpu().numpy()[0])\n",
    "            print(\"error: \", error, \"\\n\")\n",
    "            err[j,ell] += error/numit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and save\n",
    "plt.xscale('log')\n",
    "for i,c in enumerate(['b','r','g','y','b']):\n",
    "    plt.plot(ms,err[:,i],c)\n",
    "plt.show()\n",
    "\n",
    "np.savetxt(\"csrandimg_\"+img_name+\".csv\", np.vstack([ np.array(ms) ,np.array(err).T]).T , delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressive sensing on a natural image for varying number of parameters and number of measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a small image\n",
    "img_name = \"poster\" # \"F16_GT\"\n",
    "img_path = path + img_name + \".png\"\n",
    "img_pil = Image.open(img_path)\n",
    "img_np = pil_to_np(img_pil)\n",
    "img_np_small = np.array([crop_center(img_np[0],128,128)])\n",
    "img_var = np_to_var(img_np_small).type(dtype)\n",
    "\n",
    "numpoints = 8\n",
    "ms = [ int(100*np.exp(5.5/numpoints*i)) for i in range(numpoints) ] #[100,200,,17000]\n",
    "ks = [10,20,30,50,150,250]\n",
    "\n",
    "err2 = np.zeros((len(ms), len(ks)))\n",
    "\n",
    "numit = 10\n",
    "\n",
    "for q in range(numit):\n",
    "    for j,m in enumerate(ms):\n",
    "        for ell,k in enumerate(ks):\n",
    "        \n",
    "            # generate fixed input\n",
    "            num_channels = [k]*4\n",
    "            ni = get_net_input(num_channels)\n",
    "        \n",
    "            #print(\"number useful variables / number observations\", num_param(net)/m)\n",
    "            print(\"number useful variables / number observations\", (k**2*4 + k) /m)\n",
    "            print(\"number observations / number of variables\", m/n)\n",
    "            print(\"m,n,nump\",m,n,k**2*4 + k)\n",
    "\n",
    "            A = 10*torch.empty(n,m).normal_(0, 1/np.sqrt(m)).type(dtype)\n",
    "            \n",
    "            def forwardm(img):\n",
    "                X = img.view(-1 , np.prod(img.shape) )\n",
    "                return torch.mm(X,A)\n",
    "            \n",
    "            # take measurement of original image\n",
    "            measurement = forwardm(img_var).type(dtype)\n",
    "            out_img_var = dd_recovery(measurement,img_var,num_channels,ni=ni,apply_f=forwardm,num_iter=6000)\n",
    "        \n",
    "            error = snr(out_img_var.data.cpu().numpy()[0] , img_var.data.cpu().numpy()[0])\n",
    "            print(\"error: \", error, \"\\n\")\n",
    "            err2[j,ell] += error/numit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and save\n",
    "plt.xscale('log')\n",
    "for i,c in enumerate(['b','r','g','y','b','o']):\n",
    "    plt.plot(ms,err2[:,i],c)\n",
    "plt.show()\n",
    "\n",
    "np.savetxt(\"csf16img_\"+img_name+\".csv\", np.vstack([ np.array(ms) ,np.array(err2).T]).T , delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

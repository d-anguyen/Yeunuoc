{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressive Imaging with Deep Untrained Decoder Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from include import *\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import pywt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn import linear_model\n",
    "\n",
    "GPU = True\n",
    "if GPU == True:\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    print(\"num GPUs\",torch.cuda.device_count())\n",
    "    device = 'cuda'\n",
    "    if torch.cuda.device_count()==0:\n",
    "        dtype = torch.FloatTensor\n",
    "        device = 'cpu'\n",
    "else:\n",
    "    dtype = torch.FloatTensor\n",
    "    device = 'cpu'\n",
    "from scipy.fftpack import dct\n",
    "from scipy.fftpack import idct\n",
    "from scipy import io as sio \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load image and pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = 'mnist' # 'mnist' or 'celeba'\n",
    "dataset = 'celeba'\n",
    "path = './test_data/' + dataset + '/' \n",
    "img_name = dataset + '_128x128' # 1-5 (for celeba), 1-6 (for mnist)\n",
    "img_path = path + img_name + \".jpg\"\n",
    "img_pil = Image.open(img_path)\n",
    "#if dataset == 'celeba':\n",
    "#    img_pil = img_pil.crop((60,80+20,60+64,80+84)) #crop to 3 x 64 x 64\n",
    "img_np = pil_to_np(img_pil)\n",
    "print('Dimensions of input image:', img_np.shape)\n",
    "img_np = img_np / np.max(img_np)\n",
    "img_np_orig = 1*img_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display image x and convert to pytorch variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'celeba':\n",
    "    plt.imshow(img_np.transpose(1,2,0))\n",
    "else:\n",
    "    plt.imshow(img_np[0,:,:])\n",
    "    plt.gray()\n",
    "plt.axis('off')\n",
    "img_var = np_to_var(img_np).type(dtype)\n",
    "d = img_np.shape[1]\n",
    "out_ch = img_np.shape[0]\n",
    "d_image = img_np.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select and set up model to run - denoise, CS, PR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose mode, 1 (denoising) , 2 (compressed sensing), 3 (phase retrieval)\n",
    "mode = 2\n",
    "if mode==1:\n",
    "    f = 1 #(default)\n",
    "    print('Compression/denoising mode')\n",
    "    Ameas_var = 1\n",
    "    img_var_meas = img_var\n",
    "elif mode==2:\n",
    "    print('Compressed sensing mode')\n",
    "    f = 0.2 #compression rate\n",
    "    print('Compression rate is ', f)\n",
    "    m_image = int(f*d_image)\n",
    "    print('Number of measurements is ',m_image, ' for signal of length ', d_image)\n",
    "    # random Gaussian measurement matrix : A\n",
    "    Ameas = np.random.randn(m_image,d_image).astype(float)/np.sqrt(m_image)\n",
    "    Ameas_var = torch.from_numpy(Ameas).float().to(device)\n",
    "    # measurements : y = A*x\n",
    "    img_var_meas = torch.matmul(Ameas_var,img_var.to(device).reshape(d_image,1))\n",
    "if mode==3:\n",
    "    print('Compressed phase retrieval mode')    \n",
    "    f = 0.6 #compression rate\n",
    "    print('Compression rate is ', f)\n",
    "    m_image = int(f*d_image)\n",
    "    print('Number of measurements is ',m_image, ' for signal of length ', d_image)\n",
    "    # random Gaussian measurement matrix : A    \n",
    "    Ameas = np.random.randn(m_image,d_image).astype(float)/np.sqrt(m_image)\n",
    "    Ameas_var = torch.from_numpy(Ameas).float().to(device)\n",
    "    # full measurements : A*x\n",
    "    img_var_meas = torch.matmul(Ameas_var,img_var.to(device).reshape(d_image,1))      \n",
    "    # absolute valued measurements : y = |A*x|\n",
    "    img_var_meas = torch.abs(img_var_meas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use decoder architecture or DC GAN architecture\n",
    "decodetype = 'upsample' # transposeconv / upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'mnist':\n",
    "    num_channels = [25,15,10] \n",
    "#elif dataset== 'celeba':    \n",
    "#    num_channels = [120,25,15,10] \n",
    "else:\n",
    "    num_channels = [512,256,128]\n",
    "output_depth = img_np.shape[0] # number of output channels\n",
    "net = autoencodernet(num_output_channels=output_depth,num_channels_up=num_channels,need_sigmoid=True, Ameas=Ameas_var,\n",
    "                        decodetype=decodetype\n",
    "                        ).type(dtype)\n",
    "\n",
    "print(\"number of parameters: \", num_param(net))\n",
    "if decodetype == 'upsample':\n",
    "    print(net.decoder)\n",
    "elif decodetype == 'transposeconv':\n",
    "    print(net.convdecoder)\n",
    "net_in = copy.deepcopy(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invert Image from Measurements with Deep Network Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick optimization procedure\n",
    "optim = 'gd'             #'pgd' (projected gradient descent), 'gd' (gradient descent)\n",
    "if optim == 'pgd':\n",
    "    optimizer2='SGD'      #outer loop optimizer - 'SGD' (or try 'adam')\n",
    "    numit = 1000          #number of outer iterations of LS\n",
    "    LR_LS = 10            #typically 5-10 ; required for outer loop of LS\n",
    "\n",
    "    OPTIMIZER='SGD'       #inner loop optimizer - SGD or adam\n",
    "    numit_inner = 10      #number of inner loop iterations for projection\n",
    "    LR = 0.5             #typically 0.02-0.05 for pgd/inner loop of projection, higher for more complex structures\n",
    "\n",
    "    lr_decay_epoch = 500  #decay learning rates of both inner and outer optimizers\n",
    "    \n",
    "elif optim == 'gd':\n",
    "    OPTIMIZER='adam'       #optimizer - SGD or adam \n",
    "    numit = 10000         #number of iterations for SGD\n",
    "    LR = 0.0001              #typically 0.02-0.5 for gd , higher for more complex structures\n",
    "\n",
    "    optimizer2 = None                                    \n",
    "    numit_inner = None\n",
    "    LR_LS = None\n",
    "\n",
    "    lr_decay_epoch = 3000\n",
    "    \n",
    "t0 = time.time()\n",
    "mse_t, ni, net, ni_mod, in_np_img = fit( \n",
    "                            net=net,\n",
    "                            num_channels=num_channels,\n",
    "                            num_iter=numit,\n",
    "                            numit_inner = numit_inner,\n",
    "                            LR=LR,\n",
    "                            LR_LS = LR_LS,\n",
    "                            OPTIMIZER = OPTIMIZER,                          \n",
    "                            optimizer2 = optimizer2,             \n",
    "                            lr_decay_epoch = lr_decay_epoch,             \n",
    "                            img_clean_var=img_var_meas,\n",
    "                            find_best=True,\n",
    "                            Ameas = Ameas_var,\n",
    "                            model = mode,\n",
    "                            code='uniform',\n",
    "                            decodetype=decodetype,\n",
    "                            optim=optim,\n",
    "                            out_channels=out_ch        \n",
    "                            )\n",
    "t1 = time.time()\n",
    "print('\\ntime elapsed:',t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('optimizer iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.loglog(mse_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute initialization error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvls = len(num_channels)\n",
    "if decodetype == 'upsample':\n",
    "    nettype = net.decoder\n",
    "    netintype = net_in.decoder\n",
    "elif decodetype == 'transposeconv':\n",
    "    nettype = net.convdecoder\n",
    "    netintype = net_in.convdecoder\n",
    "ComputeInitErr(nettype,netintype,lvls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display reconstructed image and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img_np = net( ni.type(dtype) ).data.cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxv = np.max(img_np) \n",
    "print(\"Image inversion with Deep-Decoder, SNR: \" + str(psnr(img_np_orig,out_img_np,maxv)))  \n",
    "reconstruction_err = mse(img_np_orig,out_img_np,maxv)\n",
    "print('MSE:',reconstruction_err)\n",
    "if dataset == 'celeba':\n",
    "    plt.imshow(out_img_np.transpose(1,2,0))\n",
    "else:\n",
    "    plt.imshow(out_img_np[0,:,:])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "save_path= optim+'_'+img_name+str(int(10*f))+'.png'\n",
    "savefig=False\n",
    "if savefig:\n",
    "    plt.savefig(save_path,bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display initialization and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_img = in_np_img.data.cpu().numpy()\n",
    "maxv = np.max(img_np) \n",
    "print(\"Image at random initialization of Deep-Decoder, SNR: \" + str(psnr(img_np_orig,in_img,maxv)))  \n",
    "reconstruction_err = mse(img_np_orig,in_img,maxv)\n",
    "print('MSE:',reconstruction_err)\n",
    "if dataset == 'celeba':\n",
    "    plt.imshow(in_img[0,:,:,:].transpose(1,2,0))\n",
    "else:\n",
    "    plt.imshow(in_img[0,0,:,:])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "init_err = np.linalg.norm(out_img_np-in_img)/np.linalg.norm(out_img_np)\n",
    "print('Initialization error:', init_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image inversion with sparsity priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick sparsifying basis - Compute wavelet or cosine transforms operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = 'DCT'              # spatial, DWT, DCT\n",
    "if basis == 'DWT': #wavelet transform\n",
    "    Winv = construct_Wminv(d=img_np.shape[1],wave_name='db1') #imported from wavelet_DCT_basis.py\n",
    "    d_wav_image = int(np.sqrt(Winv.shape[1]))\n",
    "    print('Size of image:', img_np.size, ', size of wavelet transform matrix:', Winv.shape)\n",
    "elif basis == 'DCT': #DCT transform    \n",
    "    Dinv = construct_IDCT2mat(d=d)                            #imported from wavelet_DCT_basis.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify measurement operator to incorporate transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsize = img_np.shape[1]*img_np.shape[2]\n",
    "if not (mode==1):\n",
    "    A = Ameas\n",
    "    if basis=='DWT': #wavelet\n",
    "        dwsize = Winv.shape[1]\n",
    "        Aeff = np.zeros((Ameas.shape[0],dwsize*out_ch))\n",
    "        for i in range(img_np.shape[0]):   \n",
    "            Anew = np.dot(A[:,i*dsize:(i+1)*dsize],Winv)\n",
    "            Aeff[:,i*dwsize:(i+1)*dwsize] = Anew\n",
    "    elif basis=='DCT': #DCT\n",
    "        Aeff = np.zeros((Ameas.shape[0],dsize*out_ch))\n",
    "        for i in range(img_np.shape[0]):   \n",
    "            Aeff[:,i*dsize:(i+1)*dsize] = np.dot(A[:,i*dsize:(i+1)*dsize],Dinv)    \n",
    "    else:    \n",
    "        Aeff = A\n",
    "    y = img_var_meas.detach().cpu().numpy()\n",
    "elif mode==1:\n",
    "    Aeff = np.identity(np.ravel(img_var.cpu()).shape[0])\n",
    "    y = np.ravel(img_var.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store measurements and operator for MATLAB codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used for comparisons - TVAL3, SPARTA (supplementary code not provided in current version, will be updated)\n",
    "if not (mode==1):\n",
    "    save_mat = True\n",
    "    if save_mat:\n",
    "        sio.savemat('A.mat', {'A':Aeff})\n",
    "        sio.savemat('y.mat', {'y':y})\n",
    "        sio.savemat('xtrue.mat',{'x_':np.ravel(img_np)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (mode==1):\n",
    "    img_vec = sio.loadmat('xtrue.mat')['x_']\n",
    "    #img_vec = -img_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (mode==1):\n",
    "    if basis=='DWT': #wavelet\n",
    "        img_vec = np.reshape(img_vec,[img_np.shape[0],dwsize])\n",
    "        img_rec = np.zeros(img_np.shape)\n",
    "        for i in range(img_np.shape[0]):    \n",
    "            img_vec2 = np.dot(Winv,img_vec[i,:].T)\n",
    "            img_rec[i,:,:] = np.reshape(img_vec2,[img_np.shape[1],img_np.shape[2]])    \n",
    "    elif basis=='DCT': #DCT\n",
    "        img_vec = np.reshape(img_vec,[img_np.shape[0],dsize])\n",
    "        img_rec = np.zeros(img_np.shape)\n",
    "        for i in range(img_np.shape[0]):    \n",
    "            img_vec2 = np.dot(Dinv,img_vec[i,:].T)\n",
    "            img_rec[i,:,:] = np.reshape(img_vec2,[img_np.shape[1],img_np.shape[2]])                \n",
    "    else:\n",
    "        img_rec = np.reshape(img_vec,img_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressed sensing and denoising with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode==1 or mode==2:\n",
    "    t0 = time.time()\n",
    "    reg = linear_model.Lasso(alpha=1e-6) #(max_iter=10000, fit_intercept=False, tol=0.00001)\n",
    "    reg.fit(Aeff, y)  \n",
    "    img_vec = reg.coef_\n",
    "    if mode==2:\n",
    "        if basis=='DWT':\n",
    "            img_vec = np.reshape(img_vec,[img_np.shape[0],dwsize])\n",
    "            img_rec = np.zeros(img_np.shape)\n",
    "            for i in range(img_np.shape[0]):    \n",
    "                img_vec2 = np.dot(Winv,img_vec[i,:].T)\n",
    "                img_rec[i,:,:] = np.reshape(img_vec2,[img_np.shape[1],img_np.shape[2]])    \n",
    "        elif basis=='DCT':\n",
    "            img_vec = np.reshape(img_vec,[img_np.shape[0],dsize])\n",
    "            img_rec = np.zeros(img_np.shape)\n",
    "            for i in range(img_np.shape[0]):    \n",
    "                img_vec2 = np.dot(Dinv,img_vec[i,:].T)\n",
    "                img_rec[i,:,:] = np.reshape(img_vec2,[img_np.shape[1],img_np.shape[2]])                \n",
    "        else:\n",
    "            img_rec = np.reshape(img_vec,img_np.shape)\n",
    "    else:\n",
    "        img_rec = np.reshape(img_vec,img_np.shape)\n",
    "    t1 = time.time()\n",
    "    print('Time taken for Lasso:',t1-t0)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display reconstructed image and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode==1 or mode==2:\n",
    "    maxi = np.max(img_rec) \n",
    "    print(\"Image inversion with Lasso, SNR: \" + str(psnr(img_np_orig,img_rec,maxi))) \n",
    "    reconstruction_err = mse(img_np_orig,img_rec,maxi)\n",
    "    print('MSE:',reconstruction_err)\n",
    "    if out_ch==3:\n",
    "        plt.imshow(img_rec.transpose(1,2,0))\n",
    "    else: \n",
    "        plt.imshow(np.clip(img_rec[0,:,:],0,1))\n",
    "        plt.gray()\n",
    "    plt.axis('off') \n",
    "    plt.show()  \n",
    "    save_path= 'lasso_'+img_name+str(int(10*f))+'.png'\n",
    "    savefig=False\n",
    "    if savefig:\n",
    "        plt.savefig(save_path,bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

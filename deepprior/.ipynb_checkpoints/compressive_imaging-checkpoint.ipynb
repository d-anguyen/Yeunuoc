{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressive Imaging with Deep Untrained Decoder Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num GPUs 0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from include import *\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import pywt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn import linear_model\n",
    "\n",
    "GPU = True\n",
    "if GPU == True:\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    print(\"num GPUs\",torch.cuda.device_count())\n",
    "    device = 'cuda'\n",
    "    if torch.cuda.device_count()==0:\n",
    "        dtype = torch.FloatTensor\n",
    "        device = 'cpu'\n",
    "else:\n",
    "    dtype = torch.FloatTensor\n",
    "    device = 'cpu'\n",
    "from scipy.fftpack import dct\n",
    "from scipy.fftpack import idct\n",
    "from scipy import io as sio \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load image and pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of input image: (1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#dataset = 'mnist' # 'mnist' or 'celeba'\n",
    "dataset = 'mnist'\n",
    "path = './test_data/' + dataset + '/' \n",
    "img_name = dataset + '1' # 1-5 (for celeba), 1-6 (for mnist)\n",
    "img_path = path + img_name + \".jpg\"\n",
    "img_pil = Image.open(img_path)\n",
    "if dataset == 'celeba':\n",
    "    img_pil = img_pil.crop((60,80+20,60+64,80+84)) #crop to 3 x 64 x 64\n",
    "img_np = pil_to_np(img_pil)\n",
    "print('Dimensions of input image:', img_np.shape)\n",
    "img_np = img_np / np.max(img_np)\n",
    "img_np_orig = 1*img_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display image x and convert to pytorch variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAKY0lEQVR4nO3dy0tV+x/G8aV5T83y2oWSBhFBURA07AJBRRhFRDSIaBBBBNUfUEQ0aNKkGuWkSTiSQOhCkSBS0aCEJkFRYhJd1dQyzfSMfgd+4Ho+v/Y6+/jI7/0anoeve7vtOQv2h89aBdPT0wkAP4Wz/QYAzIxyAqYoJ2CKcgKmKCdgqkiFBQUFfJU7g8JC/f+0qakpmZeVlaVmP3/+zOk9/VPmz5+fmn3//v1ffCd/pqqqSuYjIyP/0jv5c9PT0wUz/XeunIApygmYopyAKcoJmKKcgCnKCZiinICpArWV8v8651RzyCSZ3VlkeXm5zCcnJ2X+69evf/Lt/JeKigqZj4+Py1x97tGMdd68eTL//fu3zGcTc05gjqGcgCnKCZiinIApygmYopyAKcoJmGLOmYPKykqZR7PEiYmJ1Cy6G2L02qOjozLPoqhIrv8mBQUzjuv+Fs0a1R5sY2OjPPvx40eZO89BmXMCcwzlBExRTsAU5QRMUU7AFOUETOnvxjGjaPUpGqVkuTVmNK6IFBcXy1y99+j2k4ODgzKP1t3GxsZSs2hUUlNTI/OhoSGZO+LKCZiinIApygmYopyAKcoJmKKcgCnKCZhizpmDkpISmUdzTjXve/bsmTz75MkTmUcrYxs2bJD52bNnU7POzk55trS0VOZqjpkkSbJw4cLULJqhRvNh55WxNFw5AVOUEzBFOQFTlBMwRTkBU5QTMEU5AVPcGnMGWXcDm5ubZd7V1ZWa1dbWyrPRY/Yi6racSZIkb968Sc2OHDkiz/b09Mg82oMtLEy/VsyfP1+eHRkZkXk0g43eWz5xa0xgjqGcgCnKCZiinIApygmYopyAKcoJmGLOmYNoZtbR0SHz7du3p2ZZH+EXPaavr69P5qtWrUrN3r17J8/u2rVL5m/fvpW52smM9i3r6+tl/vnzZ5nPJuacwBxDOQFTlBMwRTkBU5QTMEU5AVOMUmYQjSMuXLgg89OnT8tcfa1/7NgxebalpUXm165dk3m0ktbW1paaNTU1ybPRuKKhoUHm1dXVqdnw8LA8q9bNkiR+dOJs3hqTUQowx1BOwBTlBExRTsAU5QRMUU7AFOUETM3anLO4uFjm0WP0IuqRb9FMa9myZTLv7e3N5S39rbW1NTU7fvy4PKseH5gk8WP2onng8uXLU7Pnz5/Ls9EtRR88eCDz8+fPp2bd3d3ybDTHjGbXWf+9ZcGcE5hjKCdginICpignYIpyAqYoJ2CKcgKm5Jxz3rx5cs45NTUlf7iaqWWdc0avrX5+9LNv3bol8y1btsg8elzdihUrUrMPHz7Is2p+myTx7xbN+9TfbNu2bfLsnTt3ZB49OlH9TdevXy/PRruk6rabs405JzDHUE7AFOUETFFOwBTlBExRTsAU5QRMyaFXNEvMYmJiQuZq/pok8V7i5OTkH7+n/1i9erXM1f1VkyTePXz//n1qFv1e0RyzpKRE5tEuq3r9u3fvyrNnzpyR+eXLl2WuHDp0SOZXr16VeTTfzfLvJV+4cgKmKCdginICpignYIpyAqYoJ2CKcgKm8nrfWjVbyjpXyjK3inZJ7927J/OtW7fK/Pr16zI/depUavbjxw95NqtojhrlSvQ3jWasIyMjqVl0X9oDBw7I/P79+zLP50w/wj4nMMdQTsAU5QRMUU7AFOUETFFOwJSeRwSir93VyCL62j26BWQ0DlFf29fV1cmz69atk/no6KjMo7UtNS6JPtMFCxbIfHBwUOaRfK5OHT16VObq0YjR6Gzv3r0yj8ZjjrhyAqYoJ2CKcgKmKCdginICpignYIpyAqbk8Cha04nWbLKs4US3xozWj9T5hoYGeba2tlbmkZ6enpzPRp/Zt2/fcv7ZSRJ/rlkenRjNYG/cuCHzEydOpGbR7Dn63MrLy2U+NjYm89nAlRMwRTkBU5QTMEU5AVOUEzBFOQFTlBMwlWmfMxLNIpVobhXN3JT6+nqZDw8Py7ysrEzm7e3tMq+pqUnNhoaG5Nnoc6moqJB5dOvNLJ9r9FjHaAdXzXBLS0vl2a9fv8p8fHxc5o64cgKmKCdginICpignYIpyAqYoJ2CKcgKm5JwzmktFc60sj5OL7lsb7SUqCxculHl1dbXMHz9+LPP+/n6Zq1ll9JlHsj5CUO3wRp95tBMZzYfVHm00M1+5cqXMZ/MRf7niygmYopyAKcoJmKKcgCnKCZiinIApygmYknPOaI4Z7dhl2aGL5n0/f/7M+Wfv3r1b5tHvvWnTJplv3LhR5uq+ttFrV1VVyTzax4xmjer5nFnvJbxmzRqZq+emRnPvvr4+mUf3YM4yN88XrpyAKcoJmKKcgCnKCZiinIApygmYynRrzHyu4WS5RWOSJElRUfqvNjAwIM9Gq25RvnjxYpk/ffo0NYtGBtFaVjQyyDKCikSrdrdv35Z5Y2Njavb69Wt5tqOjQ+aOo5IIV07AFOUETFFOwBTlBExRTsAU5QRMUU7AlJxzRjM3tV6UJNlusxitH0XzPOX58+cyVzPSJEmSDx8+yHzHjh0y7+7uTs2iR9lllWVlrKSkRJ69dOmSzBctWiRzpbW1VeaPHj3K+We74soJmKKcgCnKCZiinIApygmYopyAKcoJmJIDvWjWGFG3zox2QaN9zmhOquZ1XV1d8uzw8LDMm5qacn7tJMnvLLO5uVnmvb29OZ+/cuWKPBvdcjS6Veq5c+dSs2iGGs3koxlttCc7G7hyAqYoJ2CKcgKmKCdginICpignYIpyAqYK1LywsLBQDhOjWaPaHYxmgVGeT9H9VXfu3CnzFy9eyHz//v2pWX9/vzz748cPmUdOnjwp84sXL6ZmIyMj8uySJUtk/vDhQ5m3tLSkZtFc3HFO+b+anp6ecTmZKydginICpignYIpyAqYoJ2CKcgKm5MpYdIvIaK1Lff2d71FJeXl5ahZ97T40NCTz0dFRma9du1bm6tac7e3t8uyrV69kvm/fPpkvXbpU5mq1KhqV3Lx5U+aHDx+WuRKtLzY0NMj806dPOb/2bOHKCZiinIApygmYopyAKcoJmKKcgCnKCZiSK2NFRUVyJyyaPak5aZbHByZJvK5WWVmZmkVzyui1Ozs7Zb5582aZf/nyJTWrq6uTZyPR5zo4OCjzgYGB1OzgwYPy7MuXL2UerX1NTEzIXKmoqJB51lW7fGJlDJhjKCdginICpignYIpyAqYoJ2CKcgKm5JyzoKBADxMDajcwmmlFj2yLzhcXF6dm0R5qZM2aNTLfs2ePzI8dO5aaRY/wi25PGe3gqtdOkiRpa2tLzaLH7EWP+IvU1NSkZtGObaSwUF+HohlsPjHnBOYYygmYopyAKcoJmKKcgCnKCZiinICpvM45AcSYcwJzDOUETFFOwBTlBExRTsAU5QRMUU7AFOUETFFOwBTlBExRTsAU5QRMUU7AFOUETFFOwBTlBExRTsAU5QRMUU7AFOUETFFOwBTlBExRTsAU5QRMUU7AFOUETFFOwBTlBExRTsAU5QRMyUcAApg9XDkBU5QTMEU5AVOUEzBFOQFTlBMw9RfSfyHdKXk7FgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if dataset == 'celeba':\n",
    "    plt.imshow(img_np.transpose(1,2,0))\n",
    "else:\n",
    "    plt.imshow(img_np[0,:,:])\n",
    "    plt.gray()\n",
    "plt.axis('off')\n",
    "img_var = np_to_var(img_np).type(dtype)\n",
    "d = img_np.shape[1]\n",
    "out_ch = img_np.shape[0]\n",
    "d_image = img_np.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select and set up model to run - denoise, CS, PR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression/denoising mode\n"
     ]
    }
   ],
   "source": [
    "#choose mode, 1 (denoising) , 2 (compressed sensing), 3 (phase retrieval)\n",
    "mode = 1\n",
    "if mode==1:\n",
    "    f = 1 #(default)\n",
    "    print('Compression/denoising mode')\n",
    "    Ameas_var = 1\n",
    "    img_var_meas = img_var\n",
    "elif mode==2:\n",
    "    print('Compressed sensing mode')\n",
    "    f = 0.2 #compression rate\n",
    "    print('Compression rate is ', f)\n",
    "    m_image = int(f*d_image)\n",
    "    print('Number of measurements is ',m_image, ' for signal of length ', d_image)\n",
    "    # random Gaussian measurement matrix : A\n",
    "    Ameas = np.random.randn(m_image,d_image).astype(float)/np.sqrt(m_image)\n",
    "    Ameas_var = torch.from_numpy(Ameas).float().to(device)\n",
    "    # measurements : y = A*x\n",
    "    img_var_meas = torch.matmul(Ameas_var,img_var.to(device).reshape(d_image,1))\n",
    "if mode==3:\n",
    "    print('Compressed phase retrieval mode')    \n",
    "    f = 0.6 #compression rate\n",
    "    print('Compression rate is ', f)\n",
    "    m_image = int(f*d_image)\n",
    "    print('Number of measurements is ',m_image, ' for signal of length ', d_image)\n",
    "    # random Gaussian measurement matrix : A    \n",
    "    Ameas = np.random.randn(m_image,d_image).astype(float)/np.sqrt(m_image)\n",
    "    Ameas_var = torch.from_numpy(Ameas).float().to(device)\n",
    "    # full measurements : A*x\n",
    "    img_var_meas = torch.matmul(Ameas_var,img_var.to(device).reshape(d_image,1))      \n",
    "    # absolute valued measurements : y = |A*x|\n",
    "    img_var_meas = torch.abs(img_var_meas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use decoder architecture or DC GAN architecture\n",
    "decodetype = 'upsample' # transposeconv / upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_scales= 3 num_channels_up= [25, 15, 10]\n",
      "number of parameters:  1800\n",
      "Sequential(\n",
      "  (dconv0): Sequential(\n",
      "    (0): ReflectionPad2d((0, 0, 0, 0))\n",
      "    (1): Conv2d(25, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (drelu0): ReLU()\n",
      "  (dbn0): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dups0): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "  (dconv1): Sequential(\n",
      "    (0): ReflectionPad2d((0, 0, 0, 0))\n",
      "    (1): Conv2d(15, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (drelu1): ReLU()\n",
      "  (dbn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dups1): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "  (dconv2): Sequential(\n",
      "    (0): ReflectionPad2d((0, 0, 0, 0))\n",
      "    (1): Conv2d(10, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if dataset == 'mnist':\n",
    "    num_channels = [25,15,10] \n",
    "elif dataset== 'celeba':    \n",
    "    num_channels = [120,25,15,10] \n",
    "else:\n",
    "    num_channels = [512,256,128]\n",
    "output_depth = img_np.shape[0] # number of output channels\n",
    "net = autoencodernet(num_output_channels=output_depth,num_channels_up=num_channels,need_sigmoid=True, Ameas=Ameas_var,\n",
    "                        decodetype=decodetype\n",
    "                        ).type(dtype)\n",
    "\n",
    "print(\"number of parameters: \", num_param(net))\n",
    "if decodetype == 'upsample':\n",
    "    print(net.decoder)\n",
    "elif decodetype == 'transposeconv':\n",
    "    print(net.convdecoder)\n",
    "net_in = copy.deepcopy(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invert Image from Measurements with Deep Network Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of latent code B1:  [1, 25, 7, 7]\n",
      "initializing latent code B1...\n",
      "not optimizing over latent code Z1\n",
      "optimize decoder with adam 0.0001\n",
      "optimizing with gradient descent...\n",
      "\n",
      "LR is set to 0.0001\n",
      "\n",
      "\n",
      "Iteration 02999   Train loss 0.021782   \n",
      "LR is set to 7e-05\n",
      "\n",
      "\n",
      "Iteration 05999   Train loss 0.005579  \n",
      "LR is set to 4.9e-05\n",
      "\n",
      "\n",
      "Iteration 08999   Train loss 0.003038   \n",
      "LR is set to 3.4299999999999993e-05\n",
      "\n",
      "\n",
      "Iteration 09999   Train loss 0.002587  \n",
      "time elapsed: 84.6992130279541\n"
     ]
    }
   ],
   "source": [
    "#pick optimization procedure\n",
    "optim = 'gd'             #'pgd' (projected gradient descent), 'gd' (gradient descent)\n",
    "if optim == 'pgd':\n",
    "    optimizer2='SGD'      #outer loop optimizer - 'SGD' (or try 'adam')\n",
    "    numit = 1000          #number of outer iterations of LS\n",
    "    LR_LS = 10            #typically 5-10 ; required for outer loop of LS\n",
    "\n",
    "    OPTIMIZER='SGD'       #inner loop optimizer - SGD or adam\n",
    "    numit_inner = 10      #number of inner loop iterations for projection\n",
    "    LR = 0.5             #typically 0.02-0.05 for pgd/inner loop of projection, higher for more complex structures\n",
    "\n",
    "    lr_decay_epoch = 500  #decay learning rates of both inner and outer optimizers\n",
    "    \n",
    "elif optim == 'gd':\n",
    "    OPTIMIZER='adam'       #optimizer - SGD or adam \n",
    "    numit = 10000         #number of iterations for SGD\n",
    "    LR = 0.0001              #typically 0.02-0.5 for gd , higher for more complex structures\n",
    "\n",
    "    optimizer2 = None                                    \n",
    "    numit_inner = None\n",
    "    LR_LS = None\n",
    "\n",
    "    lr_decay_epoch = 3000\n",
    "    \n",
    "t0 = time.time()\n",
    "mse_t, ni, net, ni_mod, in_np_img = fit( \n",
    "                            net=net,\n",
    "                            num_channels=num_channels,\n",
    "                            num_iter=numit,\n",
    "                            numit_inner = numit_inner,\n",
    "                            LR=LR,\n",
    "                            LR_LS = LR_LS,\n",
    "                            OPTIMIZER = OPTIMIZER,                          \n",
    "                            optimizer2 = optimizer2,             \n",
    "                            lr_decay_epoch = lr_decay_epoch,             \n",
    "                            img_clean_var=img_var_meas,\n",
    "                            find_best=True,\n",
    "                            Ameas = Ameas_var,\n",
    "                            model = mode,\n",
    "                            code='uniform',\n",
    "                            decodetype=decodetype,\n",
    "                            optim=optim,\n",
    "                            out_channels=out_ch        \n",
    "                            )\n",
    "t1 = time.time()\n",
    "print('\\ntime elapsed:',t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f554170da90>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('optimizer iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.loglog(mse_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute initialization error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5006195\n",
      "0.75367945\n",
      "0.78972775\n"
     ]
    }
   ],
   "source": [
    "lvls = len(num_channels)\n",
    "if decodetype == 'upsample':\n",
    "    nettype = net.decoder\n",
    "    netintype = net_in.decoder\n",
    "elif decodetype == 'transposeconv':\n",
    "    nettype = net.convdecoder\n",
    "    netintype = net_in.convdecoder\n",
    "ComputeInitErr(nettype,netintype,lvls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display reconstructed image and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img_np = net( ni.type(dtype) ).data.cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image inversion with Deep-Decoder, SNR: 25.867175041143824\n",
      "MSE: 0.020811625\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "maxv = np.max(img_np) \n",
    "print(\"Image inversion with Deep-Decoder, SNR: \" + str(psnr(img_np_orig,out_img_np,maxv)))  \n",
    "reconstruction_err = mse(img_np_orig,out_img_np,maxv)\n",
    "print('MSE:',reconstruction_err)\n",
    "if dataset == 'celeba':\n",
    "    plt.imshow(out_img_np.transpose(1,2,0))\n",
    "else:\n",
    "    plt.imshow(out_img_np[0,:,:])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "save_path= optim+'_'+img_name+str(int(10*f))+'.png'\n",
    "savefig=False\n",
    "if savefig:\n",
    "    plt.savefig(save_path,bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display initialization and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image at random initialization of Deep-Decoder, SNR: 6.390854269892577\n",
      "MSE: 0.89293826\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization error: 1.3094752\n"
     ]
    }
   ],
   "source": [
    "in_img = in_np_img.data.cpu().numpy()\n",
    "maxv = np.max(img_np) \n",
    "print(\"Image at random initialization of Deep-Decoder, SNR: \" + str(psnr(img_np_orig,in_img,maxv)))  \n",
    "reconstruction_err = mse(img_np_orig,in_img,maxv)\n",
    "print('MSE:',reconstruction_err)\n",
    "if dataset == 'celeba':\n",
    "    plt.imshow(in_img[0,:,:,:].transpose(1,2,0))\n",
    "else:\n",
    "    plt.imshow(in_img[0,0,:,:])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "init_err = np.linalg.norm(out_img_np-in_img)/np.linalg.norm(out_img_np)\n",
    "print('Initialization error:', init_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image inversion with sparsity priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick sparsifying basis - Compute wavelet or cosine transforms operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = 'DCT'              # spatial, DWT, DCT\n",
    "if basis == 'DWT': #wavelet transform\n",
    "    Winv = construct_Wminv(d=img_np.shape[1],wave_name='db1') #imported from wavelet_DCT_basis.py\n",
    "    d_wav_image = int(np.sqrt(Winv.shape[1]))\n",
    "    print('Size of image:', img_np.size, ', size of wavelet transform matrix:', Winv.shape)\n",
    "elif basis == 'DCT': #DCT transform    \n",
    "    Dinv = construct_IDCT2mat(d=d)                            #imported from wavelet_DCT_basis.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify measurement operator to incorporate transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsize = img_np.shape[1]*img_np.shape[2]\n",
    "if not (mode==1):\n",
    "    A = Ameas\n",
    "    if basis=='DWT': #wavelet\n",
    "        dwsize = Winv.shape[1]\n",
    "        Aeff = np.zeros((Ameas.shape[0],dwsize*out_ch))\n",
    "        for i in range(img_np.shape[0]):   \n",
    "            Anew = np.dot(A[:,i*dsize:(i+1)*dsize],Winv)\n",
    "            Aeff[:,i*dwsize:(i+1)*dwsize] = Anew\n",
    "    elif basis=='DCT': #DCT\n",
    "        Aeff = np.zeros((Ameas.shape[0],dsize*out_ch))\n",
    "        for i in range(img_np.shape[0]):   \n",
    "            Aeff[:,i*dsize:(i+1)*dsize] = np.dot(A[:,i*dsize:(i+1)*dsize],Dinv)    \n",
    "    else:    \n",
    "        Aeff = A\n",
    "    y = img_var_meas.detach().cpu().numpy()\n",
    "elif mode==1:\n",
    "    Aeff = np.identity(np.ravel(img_var.cpu()).shape[0])\n",
    "    y = np.ravel(img_var.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store measurements and operator for MATLAB codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used for comparisons - TVAL3, SPARTA (supplementary code not provided in current version, will be updated)\n",
    "if not (mode==1):\n",
    "    save_mat = True\n",
    "    if save_mat:\n",
    "        sio.savemat('A.mat', {'A':Aeff})\n",
    "        sio.savemat('y.mat', {'y':y})\n",
    "        sio.savemat('xtrue.mat',{'x_':np.ravel(img_np)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (mode==1):\n",
    "    img_vec = sio.loadmat('xtrue.mat')['x_']\n",
    "    #img_vec = -img_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (mode==1):\n",
    "    if basis=='DWT': #wavelet\n",
    "        img_vec = np.reshape(img_vec,[img_np.shape[0],dwsize])\n",
    "        img_rec = np.zeros(img_np.shape)\n",
    "        for i in range(img_np.shape[0]):    \n",
    "            img_vec2 = np.dot(Winv,img_vec[i,:].T)\n",
    "            img_rec[i,:,:] = np.reshape(img_vec2,[img_np.shape[1],img_np.shape[2]])    \n",
    "    elif basis=='DCT': #DCT\n",
    "        img_vec = np.reshape(img_vec,[img_np.shape[0],dsize])\n",
    "        img_rec = np.zeros(img_np.shape)\n",
    "        for i in range(img_np.shape[0]):    \n",
    "            img_vec2 = np.dot(Dinv,img_vec[i,:].T)\n",
    "            img_rec[i,:,:] = np.reshape(img_vec2,[img_np.shape[1],img_np.shape[2]])                \n",
    "    else:\n",
    "        img_rec = np.reshape(img_vec,img_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6651de3ff3b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'img_vec' is not defined"
     ]
    }
   ],
   "source": [
    "img_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressed sensing and denoising with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode==1 or mode==2:\n",
    "    t0 = time.time()\n",
    "    reg = linear_model.Lasso(alpha=1e-6) #(max_iter=10000, fit_intercept=False, tol=0.00001)\n",
    "    reg.fit(Aeff, y)  \n",
    "    img_vec = reg.coef_\n",
    "    if mode==2:\n",
    "        if basis=='DWT':\n",
    "            img_vec = np.reshape(img_vec,[img_np.shape[0],dwsize])\n",
    "            img_rec = np.zeros(img_np.shape)\n",
    "            for i in range(img_np.shape[0]):    \n",
    "                img_vec2 = np.dot(Winv,img_vec[i,:].T)\n",
    "                img_rec[i,:,:] = np.reshape(img_vec2,[img_np.shape[1],img_np.shape[2]])    \n",
    "        elif basis=='DCT':\n",
    "            img_vec = np.reshape(img_vec,[img_np.shape[0],dsize])\n",
    "            img_rec = np.zeros(img_np.shape)\n",
    "            for i in range(img_np.shape[0]):    \n",
    "                img_vec2 = np.dot(Dinv,img_vec[i,:].T)\n",
    "                img_rec[i,:,:] = np.reshape(img_vec2,[img_np.shape[1],img_np.shape[2]])                \n",
    "        else:\n",
    "            img_rec = np.reshape(img_vec,img_np.shape)\n",
    "    else:\n",
    "        img_rec = np.reshape(img_vec,img_np.shape)\n",
    "    t1 = time.time()\n",
    "    print('Time taken for Lasso:',t1-t0)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display reconstructed image and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode==1 or mode==2:\n",
    "    maxi = np.max(img_rec) \n",
    "    print(\"Image inversion with Lasso, SNR: \" + str(psnr(img_np_orig,img_rec,maxi))) \n",
    "    reconstruction_err = mse(img_np_orig,img_rec,maxi)\n",
    "    print('MSE:',reconstruction_err)\n",
    "    if out_ch==3:\n",
    "        plt.imshow(img_rec.transpose(1,2,0))\n",
    "    else: \n",
    "        plt.imshow(np.clip(img_rec[0,:,:],0,1))\n",
    "        plt.gray()\n",
    "    plt.axis('off') \n",
    "    plt.show()  \n",
    "    save_path= 'lasso_'+img_name+str(int(10*f))+'.png'\n",
    "    savefig=False\n",
    "    if savefig:\n",
    "        plt.savefig(save_path,bbox_inches='tight') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

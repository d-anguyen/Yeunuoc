{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from include import *\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import pywt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from sklearn import linear_model\n",
    "from scipy.fftpack import dct\n",
    "from scipy.fftpack import idct\n",
    "from scipy import io as sio \n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "GPU = True\n",
    "if GPU == True:\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    print(\"num GPUs\",torch.cuda.device_count())\n",
    "    device = 'cuda'\n",
    "    if torch.cuda.device_count()==0:\n",
    "        dtype = torch.FloatTensor\n",
    "        device = 'cpu'\n",
    "else:\n",
    "    dtype = torch.FloatTensor\n",
    "    device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load a test image from a dataset (now : CelebA 128x128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = 'mnist' # 'mnist' or 'celeba'\n",
    "dataset = 'celeba'\n",
    "path = './test_data/' + dataset + '/' \n",
    "img_name = dataset + '_128x128' # 1-5 (for celeba), 1-6 (for mnist)\n",
    "img_path = path + img_name + \".jpg\"\n",
    "img_pil = Image.open(img_path)\n",
    "#if dataset == 'celeba':\n",
    "#    img_pil = img_pil.crop((60,80+20,60+64,80+84)) #crop to 3 x 64 x 64\n",
    "img_np = pil_to_np(img_pil)\n",
    "print('Dimensions of input image:', img_np.shape)\n",
    "img_np = img_np / np.max(img_np)\n",
    "\n",
    "#img_np = (img_np- 1/2) *2 #convert to [-1,1] \n",
    "\n",
    "img_np_orig = 1*img_np\n",
    "\n",
    "if dataset == 'celeba':\n",
    "    plt.imshow(img_np.transpose(1,2,0))\n",
    "else:\n",
    "    plt.imshow(img_np[0,:,:])\n",
    "    plt.gray()\n",
    "plt.axis('off')\n",
    "img_var = np_to_var(img_np).type(dtype)\n",
    "d = img_np.shape[1]\n",
    "out_ch = img_np.shape[0]\n",
    "d_image = img_np.size\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Compressed sensing using generative models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Load a pretrained generative model on the dataset (now: PGGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True if torch.cuda.is_available() else False\n",
    "\n",
    "# trained on high-quality celebrity faces \"celebA\" dataset\n",
    "# this model outputs 512 x 512 pixel images\n",
    "model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub',\n",
    "                       'PGAN', model_name='celeba',\n",
    "                       pretrained=True, useGPU=use_gpu)\n",
    "# this model outputs 256 x 256 pixel images\n",
    "# model = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub',\n",
    "#                        'PGAN', model_name='celebAHQ-256',\n",
    "#                        pretrained=True, useGPU=use_gpu)\n",
    "G = model.netG\n",
    "mse = torch.nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. A=I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G0 = G(torch.zeros(1,model.config.noiseVectorDim))\n",
    "\n",
    "def exp_lr_scheduler(optimizer, epoch, init_lr=0.005, lr_decay_epoch=100, factor=0.8):\n",
    "    \"\"\"Decay learning rate by a factor of 0.5 every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (factor**(epoch // lr_decay_epoch))\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        print('\\nLR is set to {}'.format(lr))\n",
    "        print('\\n')\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return optimizer\n",
    "\n",
    "def fit(G, latentDim, y, num_iter = 2000, lr_decay_epoch = 200):\n",
    "    z = Variable(torch.zeros(1,latentDim), requires_grad = True)\n",
    "    optimizer = optim.Adam([z])\n",
    "    for i in range(num_iter):\n",
    "        #################\n",
    "        if lr_decay_epoch is not 0:\n",
    "            optimizer = exp_lr_scheduler(optimizer, i, init_lr=0.1, lr_decay_epoch=lr_decay_epoch, factor=0.8)\n",
    "            \n",
    "        #################\n",
    "        def closure():\n",
    "            optimizer.zero_grad()           \n",
    "            x = G(z)\n",
    "            loss = mse(x, y)\n",
    "            loss.backward(retain_graph=True)\n",
    "            if i % 10 == 0:\n",
    "                print('loss = {}'.format(loss))\n",
    "            return loss\n",
    "\n",
    "        loss = optimizer.step(closure)\n",
    "    print('done')\n",
    "    print('loss = {}'.format(loss))\n",
    "    #print(z)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_var = 2*img_var - 1 #convert image to [-1,1]\n",
    "\n",
    "z_hat = fit(G = G, latentDim = model.config.noiseVectorDim, y= img_var, num_iter = 1200, lr_decay_epoch = 400)    \n",
    "    \n",
    "#gen_image = (G(z_hat)+1)/2\n",
    "\n",
    "print(gen_image)\n",
    "\n",
    "#grid = torchvision.utils.make_grid(generated_images.clamp(min=-1, max=1), scale_each=True, normalize=True)\n",
    "grid = torchvision.utils.make_grid(gen_image.clamp(min=-1, max=1), scale_each=True, normalize=True)\n",
    "plt.imshow(grid.detach().permute(1, 2, 0).cpu().numpy())\n",
    "\n",
    "#print(gen_image-G0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. A= Gaussian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_image = G0.numel()\n",
    "\n",
    "f = 0.2 #compression rate\n",
    "print('Compression rate is ', f)\n",
    "m_image = int(f*d_image)\n",
    "print('Number of measurements is ',m_image, ' for signal of length ', d_image)\n",
    "\n",
    "\n",
    "# random Gaussian measurement matrix : A\n",
    "\n",
    "A = torch.randn(m_image, d_image)\n",
    "x = G0.reshape(d_image)\n",
    "y = torch.matmul(A,x)\n",
    "latentDim = model.config.noiseVectorDim\n",
    "\n",
    "def fit2(G,A,y, d_image, latentDim, num_iter = 2000, lr_decay_epoch = 200):\n",
    "    z = Variable(torch.randn(1,latentDim), requires_grad = True)\n",
    "    \n",
    "    optimizer = optim.Adam([z])\n",
    "    for i in range(num_iter):\n",
    "        ############\n",
    "        if lr_decay_epoch is not 0:\n",
    "            optimizer = exp_lr_scheduler(optimizer, i, init_lr=0.1, lr_decay_epoch = lr_decay_epoch, factor = 0.7)\n",
    "        ############\n",
    "        \n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            x_var = G(z).reshape(d_image)\n",
    "            y_var = torch.matmul(A,x_var)\n",
    "            loss = mse(y_var, y)\n",
    "            \n",
    "            loss.backward(retain_graph = True)\n",
    "            if i % lr_decay_epoch == 0:\n",
    "                print('loss = {}'.format(loss))\n",
    "            return loss\n",
    "        \n",
    "        loss = optimizer.step(closure)\n",
    "    return z\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = fit2(G, A, y, num_iter = 2000, lr_decay_epoch = 200)\n",
    "x_hat = G(z)\n",
    "\n",
    "#x_hat.reshape(x.size(0),x.size(1))\n",
    "grid = torchvision.utils.make_grid(x_hat.clamp(min=-1, max=1), scale_each=True, normalize=True)\n",
    "plt.imshow(grid.detach().permute(1, 2, 0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compressed Sensing using Deep decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use decoder architecture or DC GAN architecture\n",
    "decodetype = 'upsample' # transposeconv / upsample\n",
    "\n",
    "\n",
    "if dataset == 'mnist':\n",
    "    num_channels = [25,15,10] \n",
    "elif dataset== 'celeba':    \n",
    "    num_channels = [120,30,20,10] \n",
    "else:\n",
    "    num_channels = [128,64,32]\n",
    "    \n",
    "output_depth = img_np.shape[0] # number of output channels\n",
    "net = autoencodernet(num_output_channels=output_depth,num_channels_up=num_channels,need_sigmoid=True, \n",
    "                        decodetype=decodetype\n",
    "                        ).type(dtype)\n",
    "\n",
    "print(\"number of parameters: \", num_param(net))\n",
    "if decodetype == 'upsample':\n",
    "    print(net.decoder)\n",
    "elif decodetype == 'transposeconv':\n",
    "    print(net.convdecoder)\n",
    "net_in = copy.deepcopy(net)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''if decodetype=='upsample':\n",
    "    p = [x for x in net.decoder.parameters() ] #list of all weigths\n",
    "elif decodetype=='transposeconv':\n",
    "    p = [x for x in net.convdecoder.parameters() ] #list of all weigths\n",
    "\n",
    "weight_decay = 0\n",
    "optimizer = torch.optim.Adam(p, lr=0.001 ,weight_decay=weight_decay)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. A=I using untrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_lr_scheduler(optimizer, epoch, init_lr=0.001, lr_decay_epoch=500, factor=0.5):\n",
    "    \"\"\"Decay learning rate by a factor of 0.1 every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (factor**(epoch // lr_decay_epoch))\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        print('\\nLearning rate is set to {}'.format(lr))\n",
    "        print('\\n')\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return optimizer\n",
    "\n",
    "def fit3(net, num_channels, d_image, y, A, num_iter = 100, lr_decay_epoch = 50):\n",
    "    # compute the size of (fixed) latent vector and draw it uniformly  \n",
    "    totalupsample = 2**(len(num_channels)-1)\n",
    "    w = np.sqrt(int(d_image/3)) # =d_image / out_channels = số chiều của mỗi cạnh ảnh\n",
    "    width = int(w/(totalupsample))\n",
    "    height = int(w/(totalupsample))\n",
    "\n",
    "    shape = [1,num_channels[0], width, height]  \n",
    "    print(\"shape of latent code B1: \", shape)\n",
    "\n",
    "    print(\"initializing latent code B1...\")\n",
    "    net_input = Variable(torch.zeros(shape))\n",
    "    net_input.data.uniform_()\n",
    "    net_input.data *= 1./10\n",
    "\n",
    "    net_input_saved = net_input.data.clone()\n",
    "    noise = net_input.data.clone()\n",
    "\n",
    "    #x_in = net(net_input.type(dtype)).data.clone() #initializing image\n",
    "\n",
    "    # processing optimization\n",
    "    if decodetype=='upsample':\n",
    "        p = [x for x in net.decoder.parameters() ] #list of all weigths\n",
    "    elif decodetype=='transposeconv':\n",
    "        p = [x for x in net.convdecoder.parameters() ] #list of all weigths\n",
    "\n",
    "    weight_decay = 0\n",
    "    optimizer = torch.optim.Adam(p, lr=0.001 ,weight_decay=weight_decay)\n",
    "    mse = torch.nn.MSELoss()\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "\n",
    "        #################\n",
    "        if lr_decay_epoch is not 0:\n",
    "            optimizer = exp_lr_scheduler(optimizer, i, init_lr=0.0001, lr_decay_epoch=lr_decay_epoch,factor=0.8)\n",
    "\n",
    "        #################\n",
    "        def closure():\n",
    "            optimizer.zero_grad()           \n",
    "            x_hat = net(net_input.type(dtype))\n",
    "            \n",
    "            y_hat = torch.matmul(A,x_hat.reshape(d_image))\n",
    "            loss = mse(y_hat, y) #torch.matmul(A,x_hat)\n",
    "            loss.backward()\n",
    "            #mse_wrt_truth[i] = loss.data.cpu().numpy()\n",
    "            return loss\n",
    "\n",
    "        loss = optimizer.step(closure) \n",
    "\n",
    "        print ('Iteration %05d   Train loss %f ' % (i, loss.detach().cpu().numpy()), '\\r', end='')\n",
    "\n",
    "    return net, net_input, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 0.2 #compression rate\n",
    "print('Compression rate is ', f)\n",
    "m_image = int(f*d_image)\n",
    "print('Number of measurements is ',m_image, ' for signal of length ', d_image)\n",
    "\n",
    "\n",
    "A = torch.randn(m_image, d_image)\n",
    "x = img_var.reshape(d_image)\n",
    "y = torch.matmul(A,x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net, net_input, loss = fit3(net, num_channels, d_image, y=y, A = A, num_iter = 2000, lr_decay_epoch=0)\n",
    "x_hat = net( net_input.type(dtype) ).data.cpu().numpy()[0]\n",
    "\n",
    "plt.imshow(x_hat.transpose(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. A=Gaussian using untrained network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Compressed sensing using hybrid model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Define hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use decoder architecture or DC GAN architecture\n",
    "decodetype = 'upsample' # transposeconv / upsample\n",
    "\n",
    "\n",
    "if dataset == 'mnist':\n",
    "    num_channels = [25,15,10] \n",
    "elif dataset== 'celeba':    \n",
    "    num_channels = [120,30,20,10] \n",
    "else:\n",
    "    num_channels = [128,64,32]\n",
    "    \n",
    "output_depth = img_np.shape[0] # number of output channels\n",
    "net = autoencodernet(num_output_channels=output_depth,num_channels_up=num_channels,need_sigmoid=True, \n",
    "                        decodetype=decodetype\n",
    "                        ).type(dtype)\n",
    "\n",
    "print(\"number of parameters: \", num_param(net))\n",
    "if decodetype == 'upsample':\n",
    "    print(net.decoder)\n",
    "elif decodetype == 'transposeconv':\n",
    "    print(net.convdecoder)\n",
    "net_in = copy.deepcopy(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit4(G, net, num_channels, d_image, y, z_0, latentDim, num_iter = 200, lr_decay_epoch = 0):\n",
    "    # compute the size of (fixed) latent vector and draw it uniformly  \n",
    "    totalupsample = 2**(len(num_channels)-1)\n",
    "    w = np.sqrt(int(d_image/3)) # =d_image / out_channels = số chiều của mỗi cạnh ảnh\n",
    "    width = int(w/(totalupsample))\n",
    "    height = int(w/(totalupsample))\n",
    "\n",
    "    shape = [1,num_channels[0], width, height]  \n",
    "    print(\"shape of latent code B1: \", shape)\n",
    "\n",
    "    print(\"initializing latent code B1...\")\n",
    "    net_input = Variable(torch.zeros(shape))\n",
    "    net_input.data.uniform_()\n",
    "    net_input.data *= 1./10\n",
    "\n",
    "    net_input_saved = net_input.data.clone()\n",
    "    noise = net_input.data.clone()\n",
    "    \n",
    "    # collecting all trainable parameters\n",
    "    alpha = Variable(torch.ones(1), requires_grad=True)\n",
    "    beta = Variable(torch.zeros(1), requires_grad=True)\n",
    "    z = Variable(torch.randn(1,latentDim), requires_grad = True)\n",
    "    \n",
    "    if decodetype=='upsample':\n",
    "        p = [x for x in net.decoder.parameters() ] #list of all weigths\n",
    "    elif decodetype=='transposeconv':\n",
    "        p = [x for x in net.convdecoder.parameters() ] #list of all weigths\n",
    "    \n",
    "    \n",
    "    \n",
    "    weight_decay = 0\n",
    "    #optimizer = torch.optim.Adam(p, lr=0.001)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        {\"params\": p, \"lr\": 0.001},\n",
    "        {\"params\": alpha, \"lr\": 0.01},\n",
    "        {\"params\": beta, \"lr\": 0.01},\n",
    "        {\"params\": z, \"lr\": 0.002}\n",
    "    ],\n",
    "    lr=5e-4,\n",
    ")\n",
    "    \n",
    "    mse = torch.nn.MSELoss()\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "\n",
    "        #################\n",
    "        #if lr_decay_epoch is not 0:\n",
    "        #    optimizer = exp_lr_scheduler(optimizer, i, init_lr=0.001, lr_decay_epoch=lr_decay_epoch,factor=0.8)\n",
    "\n",
    "        #################\n",
    "        def closure():\n",
    "            optimizer.zero_grad()           \n",
    "            x_hat = alpha*G(z) + beta*net(net_input.type(dtype))\n",
    "            y_hat = x_hat\n",
    "            #y_hat = torch.matmul(A,x_hat.reshape(d_image))\n",
    "            loss = mse(x_hat, y) #torch.matmul(A,x_hat)\n",
    "            loss.backward()\n",
    "            #mse_wrt_truth[i] = loss.data.cpu().numpy()\n",
    "            return loss\n",
    "\n",
    "        loss = optimizer.step(closure) \n",
    "\n",
    "        print ('Iteration %05d   Train loss %f ' % (i, loss.detach().cpu().numpy()), '\\r', end='')\n",
    "\n",
    "    return net, net_input, z, alpha, beta, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latentDim = model.config.noiseVectorDim\n",
    "\n",
    "z0 = fit(G, latentDim, num_iter = 50, lr_decay_epoch = 0)\n",
    "\n",
    "net, net_input, z, alpha, beta, loss = fit4(G, net, num_channels,\n",
    "                                           d_image, img_var, z0,\n",
    "                                           latentDim,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat = alpha*G(z) + beta*net(net_input.type(dtype))\n",
    "x_hat_np = x_hat.data.cpu().numpy()[0]\n",
    "\n",
    "plt.imshow(x_hat_np.transpose(1,2,0))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(alpha,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.randn(3)\n",
    "uu = 2*u -1\n",
    "print(u,uu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
